{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: pillow in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: torch in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (0.20.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\development\\python-mini-projects\\trocr_datetimestampextractor\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.4/11.1 MB 16.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 3.9/8.0 MB 19.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.0 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.0 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 17.8 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 12.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 16.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.2/25.1 MB 15.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/25.1 MB 11.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/25.1 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.5/25.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/25.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.1 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, threadpoolctl, scipy, pyparsing, pyarrow, propcache, multidict, kiwisolver, joblib, fsspec, frozenlist, fonttools, dill, cycler, contourpy, attrs, aiohappyeyeballs, yarl, scikit-learn, pandas, multiprocess, matplotlib, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 attrs-24.3.0 contourpy-1.3.1 cycler-0.12.1 datasets-3.2.0 dill-0.3.8 fonttools-4.55.3 frozenlist-1.5.0 fsspec-2024.9.0 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.0 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pyparsing-3.2.1 pytz-2024.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0 tzdata-2024.2 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers pillow torch torchvision datasets scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRDataset(TorchDataset):\n",
    "    def __init__(self, dataframe, processor, image_dir):\n",
    "        self.dataframe = dataframe\n",
    "        self.processor = processor\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = Compose([ToTensor(), Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.dataframe.iloc[idx]['image_path'])\n",
    "        text = self.dataframe.iloc[idx]['text']\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = self.processor.image_processor(image, return_tensors=\"pt\").pixel_values[0]\n",
    "\n",
    "        labels = self.processor.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128).input_ids[0]\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(processor, train_csv, val_csv, image_dir):\n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    val_df = pd.read_csv(val_csv)\n",
    "\n",
    "    train_dataset = OCRDataset(train_df, processor, image_dir)\n",
    "    val_dataset = OCRDataset(val_df, processor, image_dir)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(processor, model, train_dataset, val_dataset, output_dir, training_args):\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        data_collator=None,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./input/dates/\"\n",
    "train_csv = \"./training_data/train.csv\"\n",
    "val_csv = \"./training_data/validation.csv\"\n",
    "fine_tuned_model_path = \"./trained_model/\"\n",
    "output_text_file = \"./output/trained_model_results.txt\"\n",
    "train_dataset, val_dataset = load_data(processor, train_csv, val_csv, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=fine_tuned_model_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_model(processor, model, train_dataset, val_dataset, fine_tuned_model_path, training_args)\n",
    "print(\"Fine-tuning complete. Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = VisionEncoderDecoderModel.from_pretrained(fine_tuned_model_path)\n",
    "processor = TrOCRProcessor.from_pretrained(fine_tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_fine_tuned_model(image_path, processor, model):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = processor.image_processor(image, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {image_path}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_folder(folder_path, output_file, processor, model):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            recognized_text = extract_text_with_fine_tuned_model(image_path, processor, model)\n",
    "            results.append(f\"{filename}: {recognized_text}\")\n",
    "            print(f\"Processed {filename}\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(results))\n",
    "\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images_in_folder(image_dir, output_text_file, processor, fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
