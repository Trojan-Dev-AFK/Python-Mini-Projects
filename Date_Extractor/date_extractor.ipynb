{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in d:\\development\\python-mini-projects\\date_extractor\\venv\\lib\\site-packages (0.3.10)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\development\\python-mini-projects\\date_extractor\\venv\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in d:\\development\\python-mini-projects\\date_extractor\\venv\\lib\\site-packages (from pytesseract) (10.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: python-dateutil in d:\\development\\python-mini-projects\\date_extractor\\venv\\lib\\site-packages (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\development\\python-mini-projects\\date_extractor\\venv\\lib\\site-packages (from python-dateutil) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pytesseract\n",
    "%pip install python-dateutil\n",
    "# Install tesseract exe also from link -> https://github.com/tesseract-ocr/tesseract?tab=readme-ov-file#installing-tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "from dateutil import parser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(img):\n",
    "    ocr_text = pytesseract.image_to_string(img)\n",
    "    img = Image.open(img)\n",
    "    date_regexes = [\n",
    "        r'\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}',  # e.g., 01/31/2024\n",
    "        r'\\d{1,2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{2,4}',\n",
    "    ]\n",
    "\n",
    "    hour_regex = r'\\d{1,2}'\n",
    "    minute_regex = r':\\d{2}'\n",
    "    ampm_regex = r'AM|PM'\n",
    "\n",
    "    extracted_dates = []\n",
    "    for regex in date_regexes:\n",
    "        matches = re.findall(regex, ocr_text)\n",
    "        for match in matches:\n",
    "            extracted_dates.append(match)\n",
    "\n",
    "    parsed_dates = []\n",
    "    for date_str in extracted_dates:\n",
    "        try:\n",
    "            parsed_date = parser.parse(date_str, fuzzy=True)\n",
    "            parsed_dates.append(parsed_date)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    hour_match = re.search(hour_regex, ocr_text)\n",
    "    minute_match = re.search(minute_regex, ocr_text)\n",
    "    ampm_match = re.search(ampm_regex, ocr_text)\n",
    "\n",
    "    hour = hour_match.group() if hour_match else None\n",
    "    minute = minute_match.group()[1:] if minute_match else None\n",
    "    ampm = ampm_match.group() if ampm_match else None\n",
    "\n",
    "    formatted_dates = [date.strftime(\"%d %b %Y\") for date in parsed_dates]\n",
    "\n",
    "    combined_datetime = []\n",
    "    for date in formatted_dates:\n",
    "        combined_datetime.append(f\"{date} {hour}:{minute} {ampm}\")\n",
    "\n",
    "    final_date = \"\"\n",
    "    for dt in combined_datetime:\n",
    "        # print(dt)\n",
    "        final_date = dt\n",
    "    \n",
    "    return final_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed. Results written to: ./output/extracted_dates.txt\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing images\n",
    "folder_path = \"./sample\"\n",
    "\n",
    "# Create or open a text file to write the results\n",
    "output_file_path = \"./output/extracted_dates.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "            image_path = os.path.join(folder_path, file)\n",
    "            date = get_date(image_path)\n",
    "            if date is None or date == \"\":\n",
    "                output_file.write(f\"Image: {file}, Date: Image quality low\\n\")\n",
    "            else:\n",
    "                output_file.write(f\"Image: {file}, Date: {date}\\n\")\n",
    "\n",
    "print(\"Extraction completed. Results written to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaja code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed. Results written to: ./output/extracted_dates_code1.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the path to the Tesseract executable\n",
    "# For Windows, it's something like 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "# For Linux, it might be just 'tesseract' if it's already in the PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Function to extract text from an image\n",
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image, lang='eng')\n",
    "    return text\n",
    "\n",
    "# Function to find dates in text\n",
    "def find_dates_in_text(text):\n",
    "    # Regular expression for matching various date formats (e.g., DD/MM/YYYY, MM/DD/YYYY, etc.)\n",
    "    # This is a basic pattern and might need to be adjusted or expanded depending on the date formats encountered\n",
    "    date_pattern = r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{2,4}[-/]\\d{1,2}[-/]\\d{1,2})\\b'\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    return dates\n",
    "\n",
    "# Specify your folder path containing the image files\n",
    "folder_path = './sample'\n",
    "\n",
    "# Process each file in the folder\n",
    "output_file_path = \"./output/extracted_dates_code1.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Check for common image file extensions\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            extracted_text = extract_text_from_image(file_path)\n",
    "            dates = find_dates_in_text(extracted_text)\n",
    "            # print(f\"Dates found in {filename}:Â {dates}\")\n",
    "            output_file.write(f\"Image: {filename}, Date: {dates}\\n\")\n",
    "\n",
    "print(\"Extraction completed. Results written to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaja code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed. Results written to: ./output/extracted_dates_code2.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "def preprocess_image_for_ocr(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    # Apply image pre-processing to enhance OCR recognition\n",
    "    image = image.convert('L')  # Convert to grayscale\n",
    "    image = image.filter(ImageFilter.MedianFilter())  # Apply a median filter for noise reduction\n",
    "    enhancer = ImageEnhance.Contrast(image)  # Enhance image contrast\n",
    "    image = enhancer.enhance(2)\n",
    "    image = image.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "    return image\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    text = pytesseract.image_to_string(image, lang='eng')\n",
    "    return text\n",
    "\n",
    "def find_dates_in_text(text):\n",
    "    date_pattern = r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{2,4}[-/]\\d{1,2}[-/]\\d{1,2})\\b'\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    return dates\n",
    "\n",
    "folder_path = './sample'\n",
    "\n",
    "output_file_path = \"./output/extracted_dates_code2.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image_for_ocr(file_path)\n",
    "            extracted_text = extract_text_from_image(preprocessed_image)\n",
    "            dates = find_dates_in_text(extracted_text)\n",
    "            # print(f\"Dates found in {filename}: {dates}\")\n",
    "            output_file.write(f\"Image: {filename}, Date: {dates}\\n\")\n",
    "\n",
    "print(\"Extraction completed. Results written to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaja code 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model and processor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m processor \u001b[38;5;241m=\u001b[39m TrOCRProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/trocr-base-handwritten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVisionEncoderDecoderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/trocr-base-handwritten\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_image\u001b[39m(image_path):\n\u001b[0;32m     11\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py:359\u001b[0m, in \u001b[0;36mVisionEncoderDecoderModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFast initialization is currently not supported for VisionEncoderDecoderModel. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to slow initialization...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    357\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fast_init\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:3375\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3369\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[0;32m   3370\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[0;32m   3371\u001b[0m )\n\u001b[0;32m   3373\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m   3374\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[1;32m-> 3375\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   3378\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\vision_encoder_decoder\\modeling_vision_encoder_decoder.py:196\u001b[0m, in \u001b[0;36mVisionEncoderDecoderModel.__init__\u001b[1;34m(self, config, encoder, decoder)\u001b[0m\n\u001b[0;32m    193\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_config(config\u001b[38;5;241m.\u001b[39mencoder)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m encoder\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m decoder\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:435\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_config\u001b[1;34m(cls, config, **kwargs)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    434\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m )\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1307\u001b[0m, in \u001b[0;36mPreTrainedModel._from_config\u001b[1;34m(cls, config, **kwargs)\u001b[0m\n\u001b[0;32m   1305\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1307\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;66;03m# restore default dtype if it was modified\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\trocr\\modeling_trocr.py:737\u001b[0m, in \u001b[0;36mTrOCRForCausalLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    735\u001b[0m config\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m--> 737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTrOCRDecoderWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_projection \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\trocr\\modeling_trocr.py:718\u001b[0m, in \u001b[0;36mTrOCRDecoderWrapper.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m \u001b[43mTrOCRDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\trocr\\modeling_trocr.py:478\u001b[0m, in \u001b[0;36mTrOCRDecoder.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1231\u001b[0m, in \u001b[0;36mPreTrainedModel.post_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_init\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;124;03m    A method executed at the end of each Transformer model initialization, to execute code that needs the model's\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;124;03m    modules properly initialized (such as weight initialization).\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1231\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_compatibility_gradient_checkpointing()\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:2054\u001b[0m, in \u001b[0;36mPreTrainedModel.init_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprune_heads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpruned_heads)\n\u001b[0;32m   2052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_weights:\n\u001b[0;32m   2053\u001b[0m     \u001b[38;5;66;03m# Initialize weights\u001b[39;00m\n\u001b[1;32m-> 2054\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2056\u001b[0m     \u001b[38;5;66;03m# Tie weights should be skipped when not initializing all weights\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m     \u001b[38;5;66;03m# since from_pretrained(...) calls tie weights anyways\u001b[39;00m\n\u001b[0;32m   2058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:890\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:890\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: Module.apply at line 890 (1 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:890\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:891\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    890\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 891\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1613\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_weights\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hf_initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1613\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1614\u001b[0m module\u001b[38;5;241m.\u001b[39m_is_hf_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Development\\Python-Mini-Projects\\Date_Extractor\\venv\\lib\\site-packages\\transformers\\models\\trocr\\modeling_trocr.py:417\u001b[0m, in \u001b[0;36mTrOCRPreTrainedModel._init_weights\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    415\u001b[0m std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39minit_std\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, (nn\u001b[38;5;241m.\u001b[39mLinear, nn\u001b[38;5;241m.\u001b[39mConv1d)):\n\u001b[1;32m--> 417\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m         module\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mzero_()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load the pre-trained model and processor\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    output = model.generate(pixel_values)\n",
    "    text = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    return text\n",
    "\n",
    "def find_dates_in_text(text):\n",
    "    date_pattern = r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{2,4}[-/]\\d{1,2}[-/]\\d{1,2})\\b'\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    return dates\n",
    "\n",
    "folder_path = './sample'\n",
    "\n",
    "output_file_path = \"./output/extracted_dates_code3.txt\"\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            extracted_text = extract_text_from_image(file_path)\n",
    "            dates = find_dates_in_text(extracted_text)\n",
    "            # print(f\"Dates found in {filename}: {dates}\")\n",
    "            output_file.write(f\"Image: {filename}, Date: {dates}\\n\")\n",
    "\n",
    "print(\"Extraction completed. Results written to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
